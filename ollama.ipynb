{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DevSavvy: Run an Ollama Server on Google Colab & Expose via ngrok ðŸš€\n",
        "\n",
        "## Step 1: Install Ollama âœ…\n",
        "### Ollama provides a simple API for managing LLMs."
      ],
      "metadata": {
        "id": "o6fSw-ukxNYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "id": "yhcu3b80xZtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Install & Setup ngrok âœ…\n",
        "### Download and extract the latest ngrok binary"
      ],
      "metadata": {
        "id": "jYX_Z_e8xdzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xzf ngrok-v3-stable-linux-amd64.tgz ngrok"
      ],
      "metadata": {
        "id": "7ZtwNLG7xh_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate ngrok\n",
        "\n",
        "* a ngrok auth token must be aquired in order to use it.\n",
        "\n",
        "* Follow the instruction below:\n",
        "https://ngrok.com/docs/getting-started/\n",
        "\n",
        "* Then replace your AuthToken with <NGROK_AUTH_TOKEN> below:\n"
      ],
      "metadata": {
        "id": "VHHPgjCVxlAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok authtoken <TOKEN>"
      ],
      "metadata": {
        "id": "sRccs4ESxnJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 3: Run Ollama & Expose API via ngrok ðŸš€\n",
        "### Start the Ollama server in the background"
      ],
      "metadata": {
        "id": "Q_xIT3mWxpxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKRSLVrMw1dz"
      },
      "outputs": [],
      "source": [
        "!ollama serve & ./ngrok http 11434 --host-header=\"localhost:11434\" --log stdout & sleep 5s && ollama run llama3.2"
      ]
    }
  ]
}